---
title: 'Hiểu sâu hơn về mô hình Sequence-to-sequence với bài toán Translate'
date: 2019-12-09
permalink: /posts/2019/12/seq2seq/
tags:
  - nlp
---

Mô hình Sequence-to-sequence (seq2seq) là một mô hình deep learning đã đạt được rất nhiều thành công với các bài toán như: machine translation, text summarization, image captioning...  Tuy nhiên, để hiểu rõ mô hình này cũng không phải chuyện dễ, đòi hỏi chúng ta phải nắm rõ được các thành phần cấu thành nên chúng. Đó là những gì mình nhắm đến trong bài này. Mình hy vọng các bạn đọc bài viết sẽ có thể hiểu hơn về mô hình seq2seq và xem đây như là một tư liệu trong hành trình học tập của mình.

## Mô hình Seq2Seq

Mô hình seq2seq là mô hình lấy một chuỗi các từ, chữ cái hoặc là feature của một hình ảnh làm input và output là một chuỗi khác. Một mô hình seq2seq sẽ hoạt động như thế này. 

<iframe width="560" height="215"
src="https://jalammar.github.io/images/seq2seq_1.mp4" 
frameborder="0" 
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" 
allowfullscreen>
</iframe>

Trong mô hình Translation, chuỗi đầu vào sẽ là chuỗi các từ, sau đó được xử lý và cho ra một chuỗi các từ khác.

<iframe width="560" height="215"
src="https://jalammar.github.io/images/seq2seq_2.mp4" 
frameborder="0" 
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" 
allowfullscreen>
</iframe>

Trong seq2seq model sẽ có 2 thành phần chính

- Encoder: Xử lý từng mục trong chuỗi đầu vào, sau đó biên dịch thông tin mà nó thu được và tạo thành một context vector
- Decoder: Sau khi xử lý toàn bộ chuỗi đầu vào, encoder sẽ gửi context vector cho decoder xử lý, lúc này decoder sẽ tạo ra một chuỗi output theo thứ tự

<iframe width="560" height="215"
src="https://jalammar.github.io/images/seq2seq_3.mp4" 
frameborder="0" 
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" 
allowfullscreen>
</iframe>

**Tài liệu tham khảo**

- https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/
- https://viblo.asia/p/so-luoc-word-embedding-gDVK2RAeKLj