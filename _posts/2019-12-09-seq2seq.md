---
title: 'Hiểu sâu hơn về mô hình Sequence-to-sequence với bài toán Translate'
date: 2019-12-09
permalink: /posts/2019/12/seq2seq/
tags:
  - nlp
---

Mô hình Sequence-to-sequence (seq2seq) là một mô hình deep learning đã đạt được rất nhiều thành công với các bài toán như: machine translation, text summarization, image captioning...  Tuy nhiên, để hiểu rõ mô hình này cũng không phải chuyện dễ, đòi hỏi chúng ta phải nắm rõ được các thành phần cấu thành nên chúng. Đó là những gì mình nhắm đến trong bài này. Mình hy vọng các bạn đọc bài viết sẽ có thể hiểu hơn về mô hình seq2seq và xem đây như là một tư liệu trong hành trình học tập của mình.

## Mô hình Seq-To-Seq

Mô hình seq2seq là mô hình lấy một chuỗi các từ, chữ cái hoặc là feature của một hình ảnh làm input và output là một chuỗi khác. Một mô hình seq2seq sẽ hoạt động như thế này. 

<video width="100%" height="auto" loop="" autoplay="" controls="">
  <source src="https://jalammar.github.io/images/seq2seq_1.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

Trong mô hình Translation, chuỗi đầu vào sẽ là chuỗi các từ, sau đó được xử lý và cho ra một chuỗi các từ khác.

<video width="100%" height="auto" loop="" autoplay="" controls="">
  <source src="https://jalammar.github.io/images/seq2seq_2.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

Trong seq2seq model sẽ có 2 thành phần chính

- Encoder: Xử lý từng mục trong chuỗi đầu vào, sau đó biên dịch thông tin mà nó thu được và tạo thành một **context vector**.
- Decoder: Sau khi xử lý toàn bộ chuỗi đầu vào, encoder sẽ gửi context vector cho decoder xử lý, lúc này decoder sẽ tạo ra một chuỗi output theo thứ tự.

<video width="100%" height="auto" loop="" autoplay="" controls="">
  <source src="https://jalammar.github.io/images/seq2seq_3.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

Lúc này, context vector là một vector số thực, nó là kết quả của Encoder khi đưa input vào. Hình bên dưới là một context vector với size bằng 4, nhưng trong thực tế thì context vector thường có size bằng 256, 512 hoặc 1024 tùy vào người cài đặt.

![](http://jalammar.github.io/images/context.png)

## Encoder

Bây giờ chúng ta sẽ đi sâu vào bên trong mạng encoder. Cấu tạo của mạng encoder sẽ gồm các RNN layer, hoặc LSTM, GRU (trong bài này mình sẽ mô tả RNN layer để các bạn dễ hiểu hơn). 

**Bước 1**

Quay trở lại với thiết kế, RNN sẽ nhận 2 input đầu vào tại một thời điểm: từ tại vị trí hiện tại và previous hidden state. Tuy nhiên không thể truyền một từ vào mạng được mà phải qua một số biến đổi toán học để chuyển từ đó thành vector, kỹ thuật này gọi là [word embedding](https://levanpon98.github.io/posts/2019/12/word-embedding). Thường thì khi qua bước xử lý này, các từ sẽ được biến đổi thành vector với size là 200 hoặc 300, để dễ hình dung thì mình mô tả vector này với size là 4.

![](http://jalammar.github.io/images/embedding.png)

**Bước 2**

Khi đã có được embedding vectors rồi, thì RNN tiến hành nhận 2 input vào xử lý để tạo ra output tại thời gian đó.

<video width="100%" height="auto" loop="" autoplay="" controls="">
  <source src="http://jalammar.github.io/images/RNN_1.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

Nhìn vào mô tả bên trên, bạn có thể thấy được rằng hidden state của RNN layer cuối cùng chính là context vector mà mình đã đề cập. 

## Decoder

Cấu tạo của Decoder cũng gần giống với Encoder, cũng được cấu tạo bởi RNN, tuy nhiên ở những lớp cuối cùng sẽ là softmax layer để chuyển về một phân phối giúp chúng ta chọn ra từ phù hợp. Những layer kế tiếp sẽ nhận hidden state trước đó để predict ra từ, và các hidden state sẽ được cập nhật lại và nó sẽ mang thông tin của các từ đã được predict trước đó. Quá trình decode kết thúc khi Decoder predict ra ký tự kết thúc câu.

 <video width="100%" height="auto" loop="" autoplay="" controls="">
  <source src="http://jalammar.github.io/images/seq2seq_6.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

## Nhận xét

Mô hình seq2seq là một thành tựu nổi bật của Deep learning, tuy nhiên nó vẫn còn nhiều hạn chế. Như chúng ta đã thấy encoder lấy đầu vào và chuyển đổi nó thành một vectơ có kích thước cố định và sau đó decoder đưa ra dự đoán và đưa ra chuỗi đầu ra. Nó hoạt động tốt cho chuỗi ngắn nhưng nó không thành công khi chúng ta có một chuỗi dài, mô hình trở nên khó khăn cho các encoder để ghi nhớ toàn bộ chuỗi thành một kích thước cố định vector và để nén tất cả các thông tin thành context vector. Để giải quyết vấn đề này, mô hình Attention ra đời và mình sẽ trình bày trong bài viết kế tiếp, mong các bạn đón xem

**Tài liệu tham khảo**

- [https://medium.com/analytics-vidhya/intuitive-understanding-of-seq2seq-model-attention-mechanism-in-deep-learning-1c1c24aace1e](https://medium.com/analytics-vidhya/intuitive-understanding-of-seq2seq-model-attention-mechanism-in-deep-learning-1c1c24aace1e)
- [http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/](http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)

